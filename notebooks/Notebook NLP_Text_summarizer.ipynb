{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "MnvonNr0OQta",
    "outputId": "8de387f9-1294-4588-d499-731694ba8e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2833\n"
     ]
    }
   ],
   "source": [
    "text=\"The Union Health Ministry’s ban on the retail sale and private manufacture of oxytocin, expected to kick off on September 1, is an extremely ill-thought-out one. The drug, a synthetic version of a human hormone, is a life-saver for women. Doctors use it to induce labour in pregnant women and to stem postpartum bleeding. So critical is its role in maternal health that the World Health Organization recommends it as the drug of choice in postpartum haemorrhage. The government’s ban ignores this, and is motivated instead by the misuse of the hormone in the dairy industry. Because oxytocin stimulates lactation in cattle, dairy farmers inject the drug indiscriminately to increase milk production. This has spawned several unlicensed facilities that manufacture the drug for veterinary use. It is a problem that needs solving. But the right approach would have been to strengthen regulation, and crack down on illegal production. Much is unknown about the ill-effects of oxytocin on cattle. One of the concerns was that oxytocin leads to infertility in dairy animals, and some studies show this to be true. It has also been linked to mastitis, a painful inflammation of the udder. Milk consumers worry about exposure to it through dairy products. The science behind some of these claims is unclear. In a Lok Sabha answer in 2015, the National Dairy Research Institute was quoted as saying there was no evidence that oxytocin led to infertility. A 2014 study by researchers at the National Institute of Nutrition concluded that oxytocin content in buffalo milk did not alter with injections.However, even if the ill-effects of oxytocin are real, a ban is not the answer. Oxytocin is simply too important to Indian women, 45,000 of whom die due to causes related to childbirth each year. A parallel to the situation lies in the misuse of antibiotics in humans and poultry. So heavily are these drugs used that they are causing deadly bacteria to become resistant to them. Yet, despite calls for a complete ban on over-the-counter sale of antibiotics, India has been reluctant to do so. In much of rural India, more people still die due to a lack of antibiotics than due to antibiotic-resistance. This has swung the cost-benefit ratio against outright bans. In oxytocin’s case, if only a single public sector unit manufactures the drug, as the government plans, this could lead to drug shortages and price hikes. Karnataka Antibiotics & Pharmaceuticals Limited, the drugmaker tasked with manufacturing oxytocin, has been asked to cap the price at ₹16.56 for 1 ml of a five international unit (IU) solution. However, some private manufacturers were selling it for ₹4 until now. Monopolising production will remove the low-price options from the market. Such a situation may benefit cattle, but will put the lives of many women at risk.\"\n",
    "text2=\"\"\"The Union Health Ministry’s \n",
    "ban on the retail sale and private manufacture of oxytocin,\n",
    "expected to kick off on September 1, is \n",
    "an extremely ill-thought-out one. The drug, a synthetic version\n",
    "of a human hormone, is a life-saver for women. Doctors use it \n",
    "to induce labour in pregnant women and to stem \n",
    "postpartum bleeding.\n",
    "So critical is its role in maternal health\n",
    "that the World Health Organization recommends\n",
    "it as the drug of choice in postpartum haemorrhage. \n",
    "The government’s ban ignores this, and is motivated \n",
    "instead by the misuse of the hormone in the dairy \n",
    "industry. Because oxytocin stimulates lactation in cattle, \n",
    "dairy farmers inject the drug indiscriminately to increase milk production. \n",
    "This has spawned several unlicensed facilities that manufacture the drug for veterinary use. \n",
    "It is a problem that needs solving. But the right approach would have been to strengthen regulation, \n",
    "and crack down on illegal production. Much is unknown about the ill-effects of \n",
    "oxytocin on cattle. One of the concerns was that oxytocin leads to infertility in dairy \n",
    "animals, and some studies show this to be true. It has also been linked to mastitis, \n",
    "a painful inflammation of the udder. Milk consumers worry about exposure to it through\n",
    "dairy products. The science behind some of these claims is unclear. In a Lok Sabha \n",
    "answer in 2015, the National Dairy Research Institute was quoted as saying there was \n",
    "no evidence that oxytocin led to infertility. A 2014 study by researchers at the \n",
    "National Institute of Nutrition concluded that oxytocin content in buffalo milk \n",
    "did not alter with injections.However, even if the ill-effects of oxytocin are real, \n",
    "a ban is not the answer. Oxytocin is simply too important to Indian women, 45,000 of \n",
    "whom die due to causes related to childbirth each year. A parallel to the situation\n",
    "lies in the misuse of antibiotics in humans and poultry. So heavily are \n",
    "these drugs used that they are causing deadly bacteria to become resi\n",
    "stant to them. Yet, despite calls for a complete ban on over-the-counter \n",
    "sale of antibiotics, India has been reluctant to do so. In much of rural \n",
    "India, more people still die due to a lack of antibiotics than due to \n",
    "antibiotic-resistance. This has swung the cost-benefit ratio \n",
    "against outright bans. In oxytocin’s case, if only a single \n",
    "public sector unit manufactures the drug, as the government\n",
    "plans, this could lead to drug shortages and price hikes. \n",
    "Karnataka Antibiotics & Pharmaceuticals Limited, the \n",
    "drugmaker tasked with manufacturing oxytocin, has \n",
    "been asked to cap the price at ₹16.56 for 1 ml of a \n",
    "five international unit (IU) solution. However, some \n",
    "private manufacturers were selling it for ₹4 until \n",
    "now. Monopolising production will remove the \n",
    "low-price options from the market. Such a \n",
    "situation may benefit cattle, but will put the lives of many women at risk.\n",
    "\"\"\"\n",
    "\n",
    "print(len(text))\n",
    "with open(\"judgement.txt\", \"r\",encoding='utf8') as file:\n",
    "    text1 = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "iXnbRlUbOQte",
    "outputId": "a853746e-4ef9-4c8d-91a5-30a1ed85835f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n",
      " In oxytocin’s case, if only a single public sector unit manufactures the drug, as the government plans, this could lead to drug shortages and price hikes. Karnataka Antibiotics & Pharmaceuticals Limited, the drugmaker tasked with manufacturing oxytocin, has been asked to cap the price at ₹16.56 for 1 ml of a five international unit (IU) solution.\n",
      "2018\n",
      " The establishment has Supplied manpower to the Govei.~ent College for Women Narnaul, Government college Mohindergarh, Government college Satnali, Government college Krishan nagar and co-operative bank mohindergarh. Duties of employer have also been mentioned in para 36 of EPF scheme, which are also reproduced below: - 36 “Duties of employers (1) Every employer shall send to the Commissioner, within fifteen days of the commencement of this Scheme, a consoiidated return in such form as the Commissioner may specify of the employees required or entitled to become members of the Fund showing the [basic wage, retaining allowance (if any) and dearness allowance including the cash value of any food concession] paid to each of such employees: Provided that if there is no employee who is required or entitled to become a member of the Fund, the employer shall send a ‘NIL’ return. By Way of rtime allowance, Chough it js generally in force in al] concerns js NOC earned by all employees of a Concern, It ig al] the terms of the Contract be earned by all e basic wages, (c) Conversely, any p is not basic wages, SO @drned in of employment but S of a Concern, accordance With because it it may nor mployee is excluded from dyment by Way of a Special] incentive Or work Applying the aforesaid objective the facts of the present case, 10 of 12 Order u/s 7A of The EP » 1952 for GNGGN 1576290 OD) Scansed with OREN Scanner Vv th the ) bo Establishment and the government colleges and district library that they are exempted from the purview of the Act. | I However, if the establishment have already paid any amount out of above mentioned dues, then it Is directed to Produce’ the documentary Proof of the same to the failing which in Paragraph (2) Of Rule e Of The Tribunal (Procedure) Rules, 1997, then it is directed to Submit all communications to the undersigned, immediately and keep updating of the Status of your appeal, failing Which, dues would be Tecovered from you as stated in above Paragraphs of this Order.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# If you get an error uncomment this line and download the necessary libraries\n",
    "#nltk.download()\n",
    "\n",
    "#text = \"\"\"   \"\"\"\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stopWords = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def generate_freq(words):\n",
    "    FT = dict()\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word in stopWords:\n",
    "            continue\n",
    "        \"\"\"if re.match('\\w*\\d{1,}\\w*', word):\n",
    "            continue\"\"\"\n",
    "\n",
    "        word = stemmer.stem(word)\n",
    "        if word in FT:\n",
    "            FT[word] += 1\n",
    "        else:\n",
    "            FT[word] = 1\n",
    "    return FT\n",
    "            \n",
    "\n",
    "\n",
    "def generate_sentenceValue(sentences):\n",
    "    sentenceValue = dict()\n",
    "    for sentence in sentences:\n",
    "        for word, freq in freqTable.items():\n",
    "            if word in sentence.lower():\n",
    "                if sentence in sentenceValue:\n",
    "                    sentenceValue[sentence] += freq\n",
    "                else:\n",
    "                    sentenceValue[sentence] = freq\n",
    "    sumValues = 0\n",
    "    for sentence in sentenceValue:\n",
    "        sumValues += sentenceValue[sentence]\n",
    "\n",
    "\n",
    "    average = int(sumValues / len(sentenceValue))\n",
    "    return sentenceValue, average\n",
    "\n",
    "def generate_summary(text):\n",
    "    text = text.strip().replace('\\n', ' ')\n",
    "    words = word_tokenize(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    freqTable = generate_freq(words)\n",
    "    sentenceValue, average = generate_sentenceValue(sentences)\n",
    "    summary = ''\n",
    "    for sentence in sentences:\n",
    "        if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.5 * average)):\n",
    "            summary += \" \" + sentence\n",
    "    print(len(summary))\n",
    "    print(summary)\n",
    "    \n",
    "generate_summary(text)\n",
    "generate_summary(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "an-nn0l4OQtg",
    "outputId": "603a89a9-4446-44d6-a52e-952213eeb448"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "0.009*\"order\" + 0.009*\"college\" + 0.007*\"govt\" + 0.007*\"behalf\" + 0.007*\"epf\"\n",
      "\n",
      "Topic 1:\n",
      "0.001*\"order\" + 0.001*\"govt\" + 0.001*\"behalf\" + 0.001*\"epf\" + 0.001*\"offence\"\n",
      "\n",
      "Topic 2:\n",
      "0.001*\"college\" + 0.001*\"offence\" + 0.001*\"behalf\" + 0.001*\"govt\" + 0.001*\"mentioned\"\n",
      "\n",
      "Topic 3:\n",
      "0.026*\"oxytocin\" + 0.016*\"drug\" + 0.013*\"dairy\" + 0.011*\"women\" + 0.011*\"ban\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "\n",
    "# Sample text corpus\n",
    "corpus = [\n",
    "    text,\n",
    "    text1,\n",
    "    text2\n",
    "]\n",
    "\n",
    "common = {\"act\",\"establishment\",\"employees\",\"provident\",\"scheme\", \"employer\", \"section\", \"fund\"}\n",
    "\n",
    "# Create a frozenset from the regular set\n",
    "common_frozenset = frozenset(common)\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in simple_preprocess(text):\n",
    "        if (token not in STOPWORDS) & (token not in common_frozenset) :\n",
    "            result.append(token)\n",
    "    return result\n",
    "\n",
    "processed_corpus = [preprocess(text) for text in corpus]\n",
    "\n",
    "# Create a dictionary from the processed corpus\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "\n",
    "# Convert the corpus into a bag-of-words representation\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = gensim.models.LdaModel(bow_corpus, num_topics=4, id2word=dictionary, passes=10)\n",
    "\n",
    "# Print the topics\n",
    "for idx, topic in lda_model.print_topics(num_topics=4, num_words=5):\n",
    "    print(\"Topic {}:\".format(idx))\n",
    "    print(topic)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "kxQrvBH2OQth"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A 2014 study by researchers at the National Institute of Nutrition concluded that oxytocin content in buffalo milk did not alter with injections.However, even if the ill-effects of oxytocin are real, a ban is not the answer.',\n",
       " 'In oxytocin’s case, if only a single public sector unit manufactures the drug, as the government plans, this could lead to drug shortages and price hikes.',\n",
       " 'The Union Health Ministry’s ban on the retail sale and private manufacture of oxytocin, expected to kick off on September 1, is an extremely ill-thought-out one.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Following summarization code is taken from: http://glowingpython.blogspot.in/2014/09/text-summarization-with-nltk.html\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "\n",
    "\n",
    "class FrequencySummarizer:\n",
    "    def __init__(self, min_cut = 0.1, max_cut = 0.9):\n",
    "        \"\"\"\n",
    "         Initialize the text summarizer.\n",
    "         Words that have a frequency term lower than min_cut\n",
    "         or higher than max_cut will be ignored.\n",
    "        \"\"\"\n",
    "        self._min_cut = min_cut\n",
    "        self._max_cut = max_cut\n",
    "        self._stopwords = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "    def _compute_frequencies(self, word_sent):\n",
    "        \"\"\"\n",
    "          Compute the frequency of each of word.\n",
    "          Input:\n",
    "           word_sent, a list of sentences already tokenized.\n",
    "          Output:\n",
    "           freq, a dictionary where freq[w] is the frequency of w.\n",
    "        \"\"\"\n",
    "        freq = defaultdict(int)\n",
    "        for s in word_sent:\n",
    "            for word in s:\n",
    "                if word not in self._stopwords:\n",
    "                    freq[word] += 1\n",
    "        # frequencies normalization and fitering\n",
    "        m = float(max(freq.values()))\n",
    "        for w in freq.keys():\n",
    "            freq[w] /= m\n",
    "            if freq[w] >= self._max_cut or freq[w] <= self._min_cut:\n",
    "                del freq[w]\n",
    "            return freq\n",
    "\n",
    "    def summarize(self, text, n):\n",
    "        \"\"\"\n",
    "          Return a list of n sentences\n",
    "          which represent the summary of text.\n",
    "        \"\"\"\n",
    "        sents = sent_tokenize(text)\n",
    "        assert n <= len(sents)\n",
    "        word_sent = [word_tokenize(s.lower()) for s in sents]\n",
    "        self._freq = self._compute_frequencies(word_sent)\n",
    "        ranking = defaultdict(int)\n",
    "        for i,sent in enumerate(word_sent):\n",
    "            for w in sent:\n",
    "                if w in self._freq:\n",
    "                    ranking[i] += self._freq[w]\n",
    "        sents_idx = self._rank(ranking, n)\n",
    "        return [sents[j] for j in sents_idx]\n",
    "\n",
    "    def _rank(self, ranking, n):\n",
    "        \"\"\" return the first n sentences with highest ranking \"\"\"\n",
    "        return nlargest(n, ranking, key = ranking.get)\n",
    "\n",
    "fs = FrequencySummarizer()\n",
    "fs.summarize(text,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation from https://dev.to/davidisrawi/build-a-quick-summarizer-with-python-and-nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _create_frequency_table(text_string) -> dict:\n",
    "    \"\"\"\n",
    "    we create a dictionary for the word frequency table.\n",
    "    For this, we should only use the words that are not part of the stopWords array.\n",
    "\n",
    "    Removing stop words and making frequency table\n",
    "    Stemmer - an algorithm to bring words to its root word.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(text_string)\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    freqTable = dict()\n",
    "    for word in words:\n",
    "        word = ps.stem(word)\n",
    "        if word in stopWords:\n",
    "            continue\n",
    "        if word in freqTable:\n",
    "            freqTable[word] += 1\n",
    "        else:\n",
    "            freqTable[word] = 1\n",
    "\n",
    "    return freqTable\n",
    "\n",
    "\n",
    "def _score_sentences(sentences, freqTable) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its words\n",
    "    Basic algorithm: adding the frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    sentenceValue = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        word_count_in_sentence = (len(word_tokenize(sentence)))\n",
    "        word_count_in_sentence_except_stop_words = 0\n",
    "        for wordValue in freqTable:\n",
    "            if wordValue in sentence.lower():\n",
    "                word_count_in_sentence_except_stop_words += 1\n",
    "                if sentence[:10] in sentenceValue:\n",
    "                    sentenceValue[sentence[:10]] += freqTable[wordValue]\n",
    "                else:\n",
    "                    sentenceValue[sentence[:10]] = freqTable[wordValue]\n",
    "\n",
    "        if sentence[:10] in sentenceValue:\n",
    "            sentenceValue[sentence[:10]] = sentenceValue[sentence[:10]] / word_count_in_sentence_except_stop_words\n",
    "\n",
    "        '''\n",
    "        Notice that a potential issue with our score algorithm is that long sentences will have an advantage over short sentences. \n",
    "        To solve this, we're dividing every sentence score by the number of words in the sentence.\n",
    "        \n",
    "        Note that here sentence[:10] is the first 10 character of any sentence, this is to save memory while saving keys of\n",
    "        the dictionary.\n",
    "        '''\n",
    "\n",
    "    return sentenceValue\n",
    "\n",
    "\n",
    "def _find_average_score(sentenceValue) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original text\n",
    "    average = (sumValues / len(sentenceValue))\n",
    "\n",
    "    return average\n",
    "\n",
    "\n",
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:10] in sentenceValue and sentenceValue[sentence[:10]] >= (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def run_summarization(text):\n",
    "    # 1 Create the word frequency table\n",
    "    freq_table = _create_frequency_table(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_scores = _score_sentences(sentences, freq_table)\n",
    "    threshold = _find_average_score(sentence_scores)\n",
    "    summary = _generate_summary(sentences, sentence_scores, 1.3 * threshold)\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15/03/2017\n",
      "under section 1(3)(b). ¢. |\n",
      "5. 1073 | 430136\n",
      "31275 [ 1297 998 [0\n",
      "3 of 12 Order u/s 7A of The EPF & MP Act, 1952 for GNGGN157688? [17 18=san | 16 J 2 7\n",
      "[is 19-Fep | a3 iE 0 [41448\n",
      "| 19 | 19-Mar [13 158516. gov. On behalf of govt college stanali,Sh. Sanjesh on\n",
      "behalf of Govt college Mahendergarh, Sh. th. State of M.P. 4 CIVIL APPEAL, NO(S).\n"
     ]
    }
   ],
   "source": [
    "result = run_summarization(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In oxytocin’s case, if only a single public sector unit manufactures the drug, as the government plans, this could lead to drug shortages and price hikes. The Union Health Ministry’s ban on the retail sale and private manufacture of oxytocin, expected to kick off on September 1, is an extremely ill-thought-out one. The drug, a synthetic version of a human hormone, is a life-saver for women.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from heapq import nlargest\n",
    "\n",
    "# Sample court judgement\n",
    "\n",
    "\n",
    "# Tokenize the text into sentences\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = nltk.word_tokenize(text)\n",
    "words_filtered = [word for word in words if word.casefold() not in stop_words]\n",
    "\n",
    "# Calculate frequency of each word\n",
    "freq_dist = FreqDist(words_filtered)\n",
    "\n",
    "# Calculate score for each sentence\n",
    "sentence_scores = {}\n",
    "for sentence in sentences:\n",
    "    for word in nltk.word_tokenize(sentence.lower()):\n",
    "        if word in freq_dist.keys():\n",
    "            if len(sentence.split(' ')) < 30:\n",
    "                if sentence not in sentence_scores.keys():\n",
    "                    sentence_scores[sentence] = freq_dist[word]\n",
    "                else:\n",
    "                    sentence_scores[sentence] += freq_dist[word]\n",
    "\n",
    "# Get the top N sentences with highest score\n",
    "summary_sentences = nlargest(3, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "# Print the summary\n",
    "summary = \" \".join(summary_sentences)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
